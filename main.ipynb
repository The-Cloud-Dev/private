{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (322, 512, 512, 3)\n",
      "Training mask shape: (322, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "images_path = 'images/'\n",
    "masks_path = 'masks/'\n",
    "\n",
    "# Function to load and preprocess each image\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)  # Read image using OpenCV\n",
    "    image = cv2.resize(image, (512, 512))  # Resize to 512x512\n",
    "    image = image.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def preprocess_data(image_dir, mask_dir):\n",
    "    # Get sorted list of image and mask file paths\n",
    "    image_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.png')])\n",
    "    mask_paths = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir) if fname.endswith('.png')])\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "        # Load and resize images\n",
    "        image = load_image(img_path)  # Load image and normalize\n",
    "        mask = load_image(mask_path)  # Load mask and normalize\n",
    "\n",
    "        # Initialize one-hot encoded mask\n",
    "        mask_one_hot = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.float32)\n",
    "        \n",
    "        # Encode each color channel to a specific class\n",
    "        mask_one_hot[mask[:, :, 0] > 0.5] = [1, 0, 0]  # Red (deforested)\n",
    "        mask_one_hot[mask[:, :, 1] > 0.5] = [0, 1, 0]  # Green (forested)\n",
    "        mask_one_hot[mask[:, :, 2] > 0.5] = [0, 0, 1]  # Blue (other)\n",
    "\n",
    "        # Append to lists\n",
    "        images.append(image)\n",
    "        masks.append(mask_one_hot)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_images, train_masks = preprocess_data(images_path, masks_path)\n",
    "print(f'Training data shape: {train_images.shape}')\n",
    "print(f'Training mask shape: {train_masks.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape=(512, 512, 3)):\n",
    "    # Input Layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder Path (Contracting Path)\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x1 = Dropout(0.1)(x1)\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x1_pool = MaxPooling2D((2, 2))(x1)\n",
    "    \n",
    "    x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1_pool)\n",
    "    x2 = Dropout(0.1)(x2)\n",
    "    x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x2)\n",
    "    x2_pool = MaxPooling2D((2, 2))(x2)\n",
    "    \n",
    "    x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(x2_pool)\n",
    "    x3 = Dropout(0.2)(x3)\n",
    "    x3 = Conv2D(256, (3, 3), activation='relu', padding='same')(x3)\n",
    "    x3_pool = MaxPooling2D((2, 2))(x3)\n",
    "    \n",
    "    x4 = Conv2D(512, (3, 3), activation='relu', padding='same')(x3_pool)\n",
    "    x4 = Dropout(0.2)(x4)\n",
    "    x4 = Conv2D(512, (3, 3), activation='relu', padding='same')(x4)\n",
    "    x4_pool = MaxPooling2D((2, 2))(x4)\n",
    "    \n",
    "    # Bottleneck Layer\n",
    "    x5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(x4_pool)\n",
    "    x5 = Dropout(0.3)(x5)\n",
    "    x5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(x5)\n",
    "    \n",
    "    # Decoder Path (Expanding Path)\n",
    "    x6 = UpSampling2D((2, 2))(x5)\n",
    "    x6 = Concatenate()([x6, x4])\n",
    "    x6 = Conv2D(512, (3, 3), activation='relu', padding='same')(x6)\n",
    "    x6 = Dropout(0.2)(x6)\n",
    "    x6 = Conv2D(512, (3, 3), activation='relu', padding='same')(x6)\n",
    "    \n",
    "    x7 = UpSampling2D((2, 2))(x6)\n",
    "    x7 = Concatenate()([x7, x3])\n",
    "    x7 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
    "    x7 = Dropout(0.2)(x7)\n",
    "    x7 = Conv2D(256, (3, 3), activation='relu', padding='same')(x7)\n",
    "    \n",
    "    x8 = UpSampling2D((2, 2))(x7)\n",
    "    x8 = Concatenate()([x8, x2])\n",
    "    x8 = Conv2D(128, (3, 3), activation='relu', padding='same')(x8)\n",
    "    x8 = Dropout(0.1)(x8)\n",
    "    x8 = Conv2D(128, (3, 3), activation='relu', padding='same')(x8)\n",
    "    \n",
    "    x9 = UpSampling2D((2, 2))(x8)\n",
    "    x9 = Concatenate()([x9, x1])\n",
    "    x9 = Conv2D(64, (3, 3), activation='relu', padding='same')(x9)\n",
    "    x9 = Dropout(0.1)(x9)\n",
    "    x9 = Conv2D(64, (3, 3), activation='relu', padding='same')(x9)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Conv2D(3, (1, 1), activation='softmax')(x9)\n",
    "    \n",
    "    # Create the Model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(input_shape=(512, 512, 3))\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy', MeanIoU(num_classes=3)]  # Specify num_classes=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m23/65\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17:59\u001b[0m 26s/step - accuracy: 0.5724 - loss: 0.7848"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set image size\n",
    "IMG_HEIGHT, IMG_WIDTH = 512, 512\n",
    "\n",
    "# Load and preprocess images and masks\n",
    "def load_data(img_dir, mask_dir, img_height, img_width):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_name in os.listdir(img_dir):\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        mask_path = os.path.join(mask_dir, img_name.replace('original_image', 'mask_image'))\n",
    "        \n",
    "        img = load_img(img_path, target_size=(img_height, img_width))\n",
    "        mask = load_img(mask_path, target_size=(img_height, img_width), color_mode=\"grayscale\")\n",
    "\n",
    "        img = img_to_array(img) / 255.0\n",
    "        mask = img_to_array(mask) / 255.0\n",
    "        mask = (mask > 0.5).astype(np.float32)  # Binary mask\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Define U-Net model\n",
    "def build_unet_model(input_shape):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.BatchNormalization()(c1)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = layers.BatchNormalization()(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.BatchNormalization()(c2)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = layers.BatchNormalization()(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    b = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    b = layers.BatchNormalization()(b)\n",
    "    b = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(b)\n",
    "    b = layers.BatchNormalization()(b)\n",
    "\n",
    "    # Decoder\n",
    "    u2 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(b)\n",
    "    u2 = layers.concatenate([u2, c2])\n",
    "    u2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u2)\n",
    "    u2 = layers.BatchNormalization()(u2)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u2)\n",
    "    u1 = layers.concatenate([u1, c1])\n",
    "    u1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "    u1 = layers.BatchNormalization()(u1)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(u1)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Data preparation\n",
    "img_dir = 'images'\n",
    "mask_dir = 'masks'\n",
    "images, masks = load_data(img_dir, mask_dir, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and compile the U-Net model\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "model = build_unet_model(input_shape)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    batch_size=8)\n",
    "model.save('segmentation_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
